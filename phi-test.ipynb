{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.84s/it]\n",
      "Device set to use cuda:0\n",
      "/home/julian/Programming/computer-using-agent/.venv/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is electroencephalography?\n",
      "\n",
      "Answer: Let's think step by step. Electroencephalography, often abbreviated as EEG, is a medical imaging technique used to record the electrical activity of the brain. It involves placing small, flat metal discs called electrodes on the scalp. These electrodes detect tiny electrical charges that result from the activity of brain cells. The signals are amplified and recorded by a machine, which produces a graphical representation of the brain's electrical activity.\n",
      "\n",
      "EEG is commonly used to diagnose and monitor various neurological conditions, such as epilepsy, sleep disorders, and brain injuries. It can also be used to study brain function and cognitive processes, as well as to guide brain surgery and other treatments.\n",
      "\n",
      "In summary, electroencephalography is a non-invasive method for measuring the electrical activity of the brain, which can provide valuable information about brain function and help diagnose and treat various neurological conditions.\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface.llms import HuggingFacePipeline\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=\"microsoft/Phi-3-mini-4k-instruct\",\n",
    "    task=\"text-generation\",\n",
    "    pipeline_kwargs={\n",
    "    \"max_new_tokens\": 1500,\n",
    "    \"top_k\": 50,\n",
    "    \"temperature\": 0.1,\n",
    "    },\n",
    ")\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt |    llm\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
